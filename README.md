# PSA Code Sprint 2025 ‚Äì Problem Statement 3

> **AI Co-Pilot for Level 2 Product Operations at PORTNET¬Æ**  
> Automates triage, diagnostics, and resolution planning using application logs, historical cases, and knowledge base articles.

[![Deployed on Vercel](https://img.shields.io/badge/Deployed%20on-Vercel-black?logo=vercel)](https://psa-code-sprint-25-frontend.vercel.app)

---

## üìÅ Repository Structure

```
/
‚îú‚îÄ‚îÄ Code Sprint 2025 Problem Statements copy.pdf  # Competition brief
‚îú‚îÄ‚îÄ Problem Statement 3.../                       # Provided hackathon data
‚îÇ   ‚îú‚îÄ‚îÄ Application Logs/                        # 6 microservice log files
‚îÇ   ‚îú‚îÄ‚îÄ Case Log.xlsx                            # Historical incident cases
‚îÇ   ‚îú‚îÄ‚îÄ Knowledge Base.txt                       # SOPs and procedures
‚îÇ   ‚îú‚îÄ‚îÄ Database/                                # SQL schema and sample data
‚îÇ   ‚îî‚îÄ‚îÄ Test Cases.pdf                           # Evaluation scenarios
‚îÇ
‚îú‚îÄ‚îÄ api/                                         # Vercel serverless functions (root level for Vercel)
‚îÇ   ‚îú‚îÄ‚îÄ diagnose/index.py                       # Main diagnostic endpoint
‚îÇ   ‚îú‚îÄ‚îÄ test.py                                 # Health check endpoint
‚îÇ   ‚îî‚îÄ‚îÄ hello.py                                # Simple test endpoint
‚îÇ
‚îú‚îÄ‚îÄ my_solution/                                  # ‚Üê Solution source code
‚îÇ   ‚îú‚îÄ‚îÄ backend/                                 # Core Python diagnostic engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diagnostic_system.py            # Main orchestrator
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gpt_analyzer.py                 # Azure OpenAI integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ log_searcher.py                 # Application log parser
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kb_searcher.py                  # Knowledge base search
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ case_log_searcher.py            # Historical case matcher
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                       # Configuration & paths
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webapp.py                           # Flask API for local dev
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_all_cases.py                   # Automated test suite
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                    # Python dependencies
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ frontend/                                # React + Vite UI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx                         # Main application component
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.js                          # API client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles.css                      # Styling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json                        # Frontend dependencies
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ vercel.json                             # Vercel deployment config
‚îÇ   ‚îú‚îÄ‚îÄ package.json                            # Root package config
‚îÇ   ‚îú‚îÄ‚îÄ build.js                                # Build orchestration script
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                        # Root Python dependencies
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ start_backend.sh                        # Quick start: Flask API
‚îÇ   ‚îú‚îÄ‚îÄ start_frontend.sh                       # Quick start: Vite dev server
‚îÇ   ‚îî‚îÄ‚îÄ test_setup.sh                           # Environment verification
‚îÇ
‚îî‚îÄ‚îÄ README.md                                     # This file
```

---

## üöÄ Quick Start

### Prerequisites

- **Python 3.11+** with `venv`
- **Node.js 18+** with `npm`
- **Azure OpenAI API Key** from PSA Code Sprint portal

---

### Option 1: Production (Vercel Deployment)

**Live Demo**: [https://psa-code-sprint-25-frontend.vercel.app](https://psa-code-sprint-25-frontend.vercel.app)

The application is deployed on Vercel with:
- Frontend served as static site
- API functions as serverless Python endpoints
- Environment variables configured in Vercel dashboard

---

### Option 2: Local Development

#### Step 1: Setup Backend

```bash
cd my_solution

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r backend/requirements.txt

# Configure environment variables
cd backend
cp env_template.txt .env
nano .env  # Add your Azure OpenAI API key
```

Your `.env` should contain:
```bash
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_ENDPOINT=https://psacodesprint2025.azure-api.net/
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4.1-nano
```

#### Step 2: Start Backend Server

```bash
# From my_solution/backend/
source ../venv/bin/activate
python webapp.py --port 5001
```

The Flask API will run at `http://localhost:5001`

**Test it:**
```bash
curl http://localhost:5001/health
# Should return: {"status": "ok"}
```

#### Step 3: Start Frontend

```bash
# Open a new terminal
cd my_solution/frontend
npm install
npm run dev
```

The React app will open at `http://localhost:5173`

---

### Option 3: Quick Start Scripts

We provide convenience scripts:

```bash
cd my_solution

# Terminal 1: Backend
./start_backend.sh

# Terminal 2: Frontend
./start_frontend.sh

# Test your setup
./test_setup.sh
```

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 User (Browser)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  React Frontend      ‚îÇ
         ‚îÇ  (Vite + React)      ‚îÇ
         ‚îÇ  localhost:5173      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ POST /api/diagnose
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  API Layer           ‚îÇ
         ‚îÇ  Flask (local) or    ‚îÇ
         ‚îÇ  Vercel Functions    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     L2 Diagnostic System            ‚îÇ
    ‚îÇ  (diagnostic_system.py)             ‚îÇ
    ‚îÇ                                     ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 1. Parse Alert (GPT)       ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 2. Search Application Logs ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 3. Find Similar Cases      ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 4. Search Knowledge Base   ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 5. Analyze Root Cause(GPT) ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 6. Generate Resolution(GPT)‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ 7. Create Report (GPT)     ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Azure OpenAI API    ‚îÇ
          ‚îÇ  gpt-4.1-nano        ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üß™ Testing

### Run Automated Test Suite

```bash
cd my_solution/backend
source ../venv/bin/activate
export $(grep -v '^#' .env | xargs) 2>/dev/null
python test_all_cases.py
```

This will test all scenarios from `Test Cases.pdf` and generate diagnostic reports.

### Test Individual Endpoints

```bash
# Health check
curl http://localhost:5001/health

# Diagnose endpoint
curl -X POST http://localhost:5001/api/diagnose \
  -H "Content-Type: application/json" \
  -d '{
    "alertText": "RE: Email ALR-861600 | CMAU0000020 - Duplicate Container information received"
  }'
```

---

## üéØ Key Features

### 1. Intelligent Alert Parsing
- Extracts ticket ID, module, entity ID, priority from unstructured text
- Identifies symptoms and error codes using GPT-4

### 2. Multi-Source Evidence Gathering
- **Application Logs**: Searches 6 microservice logs for relevant entries
- **Historical Cases**: Finds similar past incidents from Case Log
- **Knowledge Base**: Retrieves relevant SOPs and procedures

### 3. Root Cause Analysis
- Synthesizes evidence from multiple sources
- Provides confidence score and technical details
- Lists supporting evidence

### 4. Resolution Planning
- Step-by-step resolution instructions
- Estimated time to resolve
- SQL queries and verification steps
- Escalation recommendations

### 5. Professional Reporting
- Markdown-formatted diagnostic reports
- Clear sections for all findings
- Ready to share with team

---

## üìä Technology Stack

**Backend:**
- Python 3.13
- Azure OpenAI API (GPT-4.1-nano)
- Flask (local dev)
- Vercel Serverless Functions (production)

**Frontend:**
- React 18
- Vite 5
- Vanilla CSS

**Deployment:**
- Vercel (static site + serverless functions)
- Git-based CI/CD

**Data Processing:**
- XML parsing (Case Log without openpyxl)
- Regex-based log searching
- Text similarity matching

---

## üîß Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `AZURE_OPENAI_API_KEY` | Your Azure OpenAI API key | ‚úÖ Yes |
| `AZURE_OPENAI_ENDPOINT` | API endpoint URL | ‚úÖ Yes |
| `AZURE_OPENAI_API_VERSION` | API version | ‚úÖ Yes |
| `AZURE_OPENAI_DEPLOYMENT` | Model deployment name | ‚úÖ Yes |

**For local development**: Set in `my_solution/backend/.env`  
**For Vercel**: Set in Vercel Dashboard ‚Üí Settings ‚Üí Environment Variables

---

## üìù API Documentation

### POST `/api/diagnose`

Analyzes an alert and returns comprehensive diagnostic information.

**Request:**
```json
{
  "alertText": "RE: Email ALR-861600 | CMAU0000020 - Duplicate Container..."
}
```

**Response:**
```json
{
  "parsed": {
    "ticket_id": "ALR-861600",
    "module": "Container",
    "entity_id": "CMAU0000020",
    "priority": "Medium",
    "channel": "Email",
    "symptoms": ["duplicate", "container", "information"]
  },
  "rootCause": {
    "root_cause": "...",
    "technical_details": "...",
    "confidence": 85,
    "evidence_summary": [...]
  },
  "resolution": {
    "resolution_steps": [...],
    "estimated_time": "30 minutes",
    "escalate": false,
    "verification_steps": [...],
    "sql_queries": [...]
  },
  "report": "# Diagnostic Report\n\n...",
  "logEvidence": [...],
  "knowledgeBase": [...],
  "similarCases": [...]
}
```

### GET `/health`

Health check endpoint.

**Response:**
```json
{
  "status": "ok"
}
```

---

## üêõ Troubleshooting

### Port Conflicts (macOS)

If port 5000 is occupied by macOS Control Center:
```bash
python webapp.py --port 5001
```

Then update `frontend/vite.config.js`:
```js
proxy: {
  '/api': {
    target: 'http://localhost:5001',  // Changed from 5000
    changeOrigin: true,
  },
}
```

### Missing Dependencies

```bash
# Backend
cd my_solution
source venv/bin/activate
pip install -r backend/requirements.txt

# Frontend
cd frontend
npm install
```

### API Key Issues

Verify your `.env` file:
```bash
cd my_solution/backend
cat .env
```

Ensure no extra spaces or quotes around the API key.

### Vercel Deployment Issues

1. Check Root Directory setting: Should be `my_solution`
2. Check environment variables in Vercel Dashboard
3. View function logs: Vercel Dashboard ‚Üí Functions ‚Üí Logs

---

## üìö Additional Documentation

- **`my_solution/STARTUP_GUIDE.md`** - Comprehensive setup guide
- **`my_solution/VERCEL_DEPLOYMENT.md`** - Vercel deployment details
- **`my_solution/VERCEL_QUICK_FIX.md`** - Common deployment fixes
- **`my_solution/FIXES_APPLIED.md`** - Technical fixes log
- **`my_solution/backend/docs/`** - Backend implementation docs

---

## üéì Design Decisions

### Why No External Excel Libraries?
We parse `Case Log.xlsx` using Python's built-in `zipfile` and `xml.etree.ElementTree` to avoid heavy dependencies like `openpyxl` or `pandas`. This keeps the deployment lightweight for serverless environments.

### Why `/api` at Root Level?
- Vercel requires serverless functions to be in `/api` directory at repository root
- This is a Vercel platform requirement for automatic function detection
- `/api` imports from `/my_solution/backend` for the actual diagnostic logic
- This separation keeps most code organized in `/my_solution` while meeting Vercel's requirements

### Why GPT-4.1-nano?
Balances performance and cost for rapid diagnostics while maintaining high accuracy for production-critical operations.

---

## üë• Team & Competition

**PSA Code Sprint 2025**  
**Problem Statement 3**: Redefining Level 2 Product Ops

Built for Singapore's Port Operations with ‚ù§Ô∏è

---

## üìÑ License

This project is submitted as part of PSA Code Sprint 2025.

---

## üöÄ Live Demo

**Try it now**: [https://psa-code-sprint-25-frontend.vercel.app](https://psa-code-sprint-25-frontend.vercel.app)

Paste an alert and watch the AI co-pilot diagnose it in seconds! üéØ
